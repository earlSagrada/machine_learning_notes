{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "embedding_try.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPyDHrXdDa5OZx8NA20eAiz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/earlSagrada/machine_learning_notes/blob/master/embedding_try.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd9KCuWUw35W",
        "colab_type": "text"
      },
      "source": [
        "Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOywkl9Vw2Ii",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "3c845942-1ec1-4f73-bcb9-6d02e8445bac"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "# implements specialized container datatypes\n",
        "import collections\n",
        "import io\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from IPython import display\n",
        "from sklearn import metrics\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "'''\n",
        "in tensorflow2 we should use:\n",
        "  tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "but one is suggested to use python logging module instead:\n",
        "  import logging\n",
        "  logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
        "before importing tensorflow\n",
        "'''\n",
        "train_url = 'https://download.mlcc.google.cn/mledu-datasets/sparse-data-embedding/train.tfrecord'\n",
        "# Downloads a file from a URL if it not already in the cache\n",
        "# tf.keras.utils.get_file(fname, origin)\n",
        "# [-1] the last but one item in the URL\n",
        "# just a filename\n",
        "train_path = tf.keras.utils.get_file(train_url.split('/')[-1], train_url)\n",
        "\n",
        "test_url = 'https://download.mlcc.google.cn/mledu-datasets/sparse-data-embedding/test.tfrecord'\n",
        "test_path = tf.keras.utils.get_file(test_url.split('/')[-1], test_url)\n",
        "\n",
        "\n",
        "def _parse_function(record):\n",
        "  \"\"\"Extracts features and labels\n",
        "\n",
        "  Args:\n",
        "    record: File path to a TFRecord file\n",
        "  Returns:\n",
        "    A `tuple` `(labels, features)`:\n",
        "      features: A dict of tensors representing the features\n",
        "      labels: A tensor with the corresponding labels.\n",
        "  \"\"\"\n",
        "  features = {\n",
        "      \"terms\": tf.VarLenFeature(dtype=tf.string), # terms are strings of varying lengths\n",
        "      \"labels\": tf.FixedLenFeature(shape=[1], dtype=tf.float32) # labels are 0 or 1\n",
        "  }\n",
        "  \n",
        "  # parse 解析 ???\n",
        "  parsed_features = tf.parse_single_example(record, features)\n",
        "\n",
        "  terms = parsed_features['terms'].values\n",
        "  labels = parsed_features['labels']\n",
        "\n",
        "  return {'terms':terms}, labels\n",
        "\n",
        "## Ensure the function works well\n",
        "# Create the Dataset object\n",
        "ds = tf.data.TFRecordDataset(train_path)\n",
        "# Map features and labels with the parse function\n",
        "# ds(dataset) --> _parse_function --> parsed ???\n",
        "ds = ds.map(_parse_function)\n",
        "\n",
        "ds\n",
        "\n",
        "# Get the first sample from ds\n",
        "# Use __iter__() in tensorflow2 ???\n",
        "n = ds.make_one_shot_iterator().get_next()\n",
        "# Create a Session object\n",
        "# tf.compat.v1.Session\n",
        "sess = tf.Session()\n",
        "sess.run(n)\n",
        "\n",
        "\n",
        "## Create an input_fn that parses the tf.Examples from the given files,\n",
        "## and split them into features and targets\n",
        "def _input_fn(input_filenames, num_epochs=None, shuffle=True):\n",
        "\n",
        "  # Same code above; create a dataset and map features and labels\n",
        "  ds = tf.data.TFRecordDataset(input_filenames)\n",
        "  ds = ds.map(_parse_function)\n",
        "\n",
        "  if shuffle:\n",
        "    # Randomly shufles the items in the dataset\n",
        "    ds = ds.shuffle(10000)\n",
        "  \n",
        "  # Our feature data is variable-length, so we pad 填补 and batch\n",
        "  # each field of the dataset structure to whatever size is necessary\n",
        "  ds = ds.padded_batch(25, ds.output_shapes) # batch_size, padded_shapes ???\n",
        "\n",
        "  # Repeats this dataset so each original value is seen count times\n",
        "  ds = ds.repeat(num_epochs)\n",
        "\n",
        "\n",
        "  # Return the next batch of data\n",
        "  features, labels = ds.make_one_shot_iterator().get_next()\n",
        "  return features, labels\n",
        "\n",
        "\n",
        "# 50 informative terms that compose our model vocabulary\n",
        "informative_terms = (\"bad\", \"great\", \"best\", \"worst\", \"fun\", \"beautiful\",\n",
        "                     \"excellent\", \"poor\", \"boring\", \"awful\", \"terrible\",\n",
        "                     \"definitely\", \"perfect\", \"liked\", \"worse\", \"waste\",\n",
        "                     \"entertaining\", \"loved\", \"unfortunately\", \"amazing\",\n",
        "                     \"enjoyed\", \"favorite\", \"horrible\", \"brilliant\", \"highly\",\n",
        "                     \"simple\", \"annoying\", \"today\", \"hilarious\", \"enjoyable\",\n",
        "                     \"dull\", \"fantastic\", \"poorly\", \"fails\", \"disappointing\",\n",
        "                     \"disappointment\", \"not\", \"him\", \"her\", \"good\", \"time\",\n",
        "                     \"?\", \".\", \"!\", \"movie\", \"film\", \"action\", \"comedy\",\n",
        "                     \"drama\", \"family\")\n",
        "\n",
        "# key: A unique string identifying the input feature\n",
        "terms_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(key=\"terms\", vocabulary_list=informative_terms)\n",
        "\n",
        "\n",
        "# Construct LinearClassifier\n",
        "my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
        "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "\n",
        "feature_columns = [terms_feature_column]\n",
        "\n",
        "\n",
        "classifier = tf.estimator.LinearClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    optimizer=my_optimizer,\n",
        ")\n",
        "\n",
        "classifier.train(\n",
        "    input_fn=lambda: _input_fn([train_path]),\n",
        "    steps=1000\n",
        ")\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "    input_fn=lambda: _input_fn([train_path]),\n",
        "    steps=1000\n",
        ")\n",
        "print(\"Training set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "    input_fn=lambda: _input_fn([train_path]),\n",
        "    steps=1000\n",
        ")\n",
        "print(\"Training set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")\n",
        "\n",
        "\n",
        "\n",
        "## Use a DNN model\n",
        "classifier_dnn = tf.estimator.DNNClassifier(\n",
        "    feature_columns=[tf.feature_column.indicator_column(terms_feature_column)],\n",
        "    hidden_units=[20,20],\n",
        "    optimizer=my_optimizer,\n",
        ")\n",
        "\n",
        "\n",
        "try:\n",
        "  classifier_dnn.train(\n",
        "    input_fn=lambda: _input_fn([train_path]),\n",
        "    steps=1000\n",
        "  )\n",
        "  \n",
        "  evaluation_metrics = classifier_dnn.evaluate(\n",
        "    input_fn=lambda: _input_fn([train_path]),\n",
        "    steps=1\n",
        "  )\n",
        "  print(\"Training set metrics:\")\n",
        "  for m in evaluation_metrics:\n",
        "    print(m, evaluation_metrics[m])\n",
        "  print(\"---\")\n",
        "\n",
        "  evaluation_metrics = classifier_dnn.evaluate(\n",
        "    input_fn=lambda: _input_fn([train_path]),\n",
        "    steps=1\n",
        "  )\n",
        "  print(\"Training set metrics:\")\n",
        "  for m in evaluation_metrics:\n",
        "    print(m, evaluation_metrics[m])\n",
        "  print(\"---\")\n",
        "except ValueError as err:\n",
        "  print(err)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set metrics:\n",
            "accuracy 0.78764\n",
            "accuracy_baseline 0.5\n",
            "auc 0.8718103\n",
            "auc_precision_recall 0.86407375\n",
            "average_loss 0.45212543\n",
            "label/mean 0.5\n",
            "loss 11.303136\n",
            "precision 0.7827318\n",
            "prediction/mean 0.48114967\n",
            "recall 0.79632\n",
            "global_step 1000\n",
            "---\n",
            "Training set metrics:\n",
            "accuracy 0.78764\n",
            "accuracy_baseline 0.5\n",
            "auc 0.8718103\n",
            "auc_precision_recall 0.86407375\n",
            "average_loss 0.45212457\n",
            "label/mean 0.5\n",
            "loss 11.303114\n",
            "precision 0.7827318\n",
            "prediction/mean 0.48114967\n",
            "recall 0.79632\n",
            "global_step 1000\n",
            "---\n",
            "Training set metrics:\n",
            "accuracy 0.84\n",
            "accuracy_baseline 0.56\n",
            "auc 0.9577922\n",
            "auc_precision_recall 0.94508237\n",
            "average_loss 0.32146832\n",
            "label/mean 0.44\n",
            "loss 8.036708\n",
            "precision 0.7692308\n",
            "prediction/mean 0.4295966\n",
            "recall 0.90909094\n",
            "global_step 1000\n",
            "---\n",
            "Training set metrics:\n",
            "accuracy 0.76\n",
            "accuracy_baseline 0.56\n",
            "auc 0.82142854\n",
            "auc_precision_recall 0.6763135\n",
            "average_loss 0.51706225\n",
            "label/mean 0.44\n",
            "loss 12.926556\n",
            "precision 0.6923077\n",
            "prediction/mean 0.47098482\n",
            "recall 0.8181818\n",
            "global_step 1000\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}